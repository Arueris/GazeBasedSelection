{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Start \n",
    "\n",
    "We begin with a leave-one-out participant to get for every participant a number of wrong selections and how many it would be with the help of TCNAE."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save folder\n",
    "import os\n",
    "import utils\n",
    "\n",
    "save_folder = utils.create_unique_folder('Results/PowerMeasurements')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Condition: gaze\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Bjoern\\anaconda3\\envs\\MAIA\\Lib\\site-packages\\onnxscript\\converter.py:820: FutureWarning: 'onnxscript.values.Op.param_schemas' is deprecated in version 0.1 and will be removed in the future. Please use '.op_signature' instead.\n",
      "  param_schemas = callee.param_schemas()\n",
      "c:\\Users\\Bjoern\\anaconda3\\envs\\MAIA\\Lib\\site-packages\\onnxscript\\converter.py:820: FutureWarning: 'onnxscript.values.OnnxFunction.param_schemas' is deprecated in version 0.1 and will be removed in the future. Please use '.op_signature' instead.\n",
      "  param_schemas = callee.param_schemas()\n",
      "Participant 1/52 gaze: 100%|██████████| 400/400 [00:27<00:00, 14.39it/s, Loss=0.0406]\n",
      "Participant 2/52 gaze: 100%|██████████| 400/400 [00:20<00:00, 19.13it/s, Loss=0.0404]\n",
      "Participant 3/52 gaze: 100%|██████████| 400/400 [00:18<00:00, 21.69it/s, Loss=0.052] \n",
      "Participant 4/52 gaze: 100%|██████████| 400/400 [00:18<00:00, 22.11it/s, Loss=0.0567]\n",
      "Participant 5/52 gaze: 100%|██████████| 400/400 [00:17<00:00, 22.66it/s, Loss=0.0515]\n",
      "Participant 6/52 gaze: 100%|██████████| 400/400 [00:18<00:00, 22.04it/s, Loss=0.0592]\n",
      "Participant 7/52 gaze: 100%|██████████| 400/400 [00:17<00:00, 22.22it/s, Loss=0.0516]\n",
      "Participant 8/52 gaze: 100%|██████████| 400/400 [00:17<00:00, 22.23it/s, Loss=0.043] \n",
      "Participant 9/52 gaze: 100%|██████████| 400/400 [00:18<00:00, 22.02it/s, Loss=0.0608]\n",
      "Participant 10/52 gaze: 100%|██████████| 400/400 [00:17<00:00, 22.29it/s, Loss=0.0438]\n",
      "Participant 11/52 gaze: 100%|██████████| 400/400 [00:19<00:00, 21.00it/s, Loss=0.0508]\n",
      "Participant 12/52 gaze: 100%|██████████| 400/400 [00:18<00:00, 21.61it/s, Loss=0.0546]\n",
      "Participant 13/52 gaze: 100%|██████████| 400/400 [00:17<00:00, 22.35it/s, Loss=0.0427]\n",
      "Participant 14/52 gaze: 100%|██████████| 400/400 [00:18<00:00, 21.60it/s, Loss=0.0559]\n",
      "Participant 15/52 gaze: 100%|██████████| 400/400 [00:24<00:00, 16.56it/s, Loss=0.0419]\n",
      "Participant 16/52 gaze: 100%|██████████| 400/400 [00:19<00:00, 20.64it/s, Loss=0.0427]\n",
      "Participant 17/52 gaze: 100%|██████████| 400/400 [00:18<00:00, 21.43it/s, Loss=0.0513]\n",
      "Participant 18/52 gaze: 100%|██████████| 400/400 [00:19<00:00, 20.78it/s, Loss=0.0599]\n",
      "Participant 19/52 gaze: 100%|██████████| 400/400 [00:17<00:00, 22.80it/s, Loss=0.0599]\n",
      "Participant 20/52 gaze: 100%|██████████| 400/400 [00:17<00:00, 22.74it/s, Loss=0.0403]\n",
      "Participant 21/52 gaze: 100%|██████████| 400/400 [00:18<00:00, 21.94it/s, Loss=0.0455]\n",
      "Participant 22/52 gaze: 100%|██████████| 400/400 [00:17<00:00, 22.45it/s, Loss=0.0612]\n",
      "Participant 23/52 gaze: 100%|██████████| 400/400 [00:17<00:00, 23.41it/s, Loss=0.0565]\n",
      "Participant 24/52 gaze: 100%|██████████| 400/400 [00:17<00:00, 22.49it/s, Loss=0.0535]\n",
      "Participant 25/52 gaze: 100%|██████████| 400/400 [00:17<00:00, 22.75it/s, Loss=0.0518]\n",
      "Participant 26/52 gaze: 100%|██████████| 400/400 [00:17<00:00, 23.42it/s, Loss=0.0525]\n",
      "Participant 27/52 gaze: 100%|██████████| 400/400 [00:17<00:00, 23.50it/s, Loss=0.0476]\n",
      "Participant 28/52 gaze: 100%|██████████| 400/400 [00:16<00:00, 23.90it/s, Loss=0.0553]\n",
      "Participant 29/52 gaze: 100%|██████████| 400/400 [00:17<00:00, 23.23it/s, Loss=0.0543]\n",
      "Participant 30/52 gaze: 100%|██████████| 400/400 [00:16<00:00, 23.92it/s, Loss=0.0413]\n",
      "Participant 31/52 gaze: 100%|██████████| 400/400 [00:17<00:00, 23.20it/s, Loss=0.06]  \n",
      "Participant 32/52 gaze: 100%|██████████| 400/400 [00:16<00:00, 24.37it/s, Loss=0.0513]\n",
      "Participant 33/52 gaze: 100%|██████████| 400/400 [00:16<00:00, 24.33it/s, Loss=0.0549]\n",
      "Participant 34/52 gaze: 100%|██████████| 400/400 [00:16<00:00, 23.95it/s, Loss=0.0563]\n",
      "Participant 35/52 gaze: 100%|██████████| 400/400 [00:16<00:00, 24.36it/s, Loss=0.0514]\n",
      "Participant 36/52 gaze: 100%|██████████| 400/400 [00:16<00:00, 23.99it/s, Loss=0.0582]\n",
      "Participant 37/52 gaze: 100%|██████████| 400/400 [00:16<00:00, 23.99it/s, Loss=0.0588]\n",
      "Participant 38/52 gaze: 100%|██████████| 400/400 [00:16<00:00, 23.72it/s, Loss=0.0603]\n",
      "Participant 39/52 gaze: 100%|██████████| 400/400 [00:17<00:00, 22.57it/s, Loss=0.0601]\n",
      "Participant 40/52 gaze: 100%|██████████| 400/400 [00:16<00:00, 24.03it/s, Loss=0.0485]\n",
      "Participant 41/52 gaze: 100%|██████████| 400/400 [00:16<00:00, 23.72it/s, Loss=0.0587]\n",
      "Participant 42/52 gaze: 100%|██████████| 400/400 [00:16<00:00, 24.19it/s, Loss=0.0445]\n",
      "Participant 43/52 gaze: 100%|██████████| 400/400 [00:17<00:00, 23.19it/s, Loss=0.0564]\n",
      "Participant 44/52 gaze: 100%|██████████| 400/400 [00:17<00:00, 22.98it/s, Loss=0.0528]\n",
      "Participant 45/52 gaze: 100%|██████████| 400/400 [00:18<00:00, 21.47it/s, Loss=0.0539]\n",
      "Participant 46/52 gaze: 100%|██████████| 400/400 [00:16<00:00, 23.63it/s, Loss=0.0538]\n",
      "Participant 47/52 gaze: 100%|██████████| 400/400 [00:17<00:00, 23.04it/s, Loss=0.0624]\n",
      "Participant 48/52 gaze: 100%|██████████| 400/400 [00:17<00:00, 22.61it/s, Loss=0.0515]\n",
      "Participant 49/52 gaze: 100%|██████████| 400/400 [00:17<00:00, 23.33it/s, Loss=0.0413]\n",
      "Participant 50/52 gaze: 100%|██████████| 400/400 [00:17<00:00, 23.42it/s, Loss=0.0536]\n",
      "Participant 51/52 gaze: 100%|██████████| 400/400 [00:17<00:00, 23.25it/s, Loss=0.0549]\n",
      "Participant 52/52 gaze: 100%|██████████| 400/400 [00:17<00:00, 22.97it/s, Loss=0.0485]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Condition: headAndGaze\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Participant 1/52 headAndGaze: 100%|██████████| 400/400 [00:19<00:00, 20.11it/s, Loss=0.0751]\n",
      "Participant 2/52 headAndGaze: 100%|██████████| 400/400 [00:18<00:00, 21.29it/s, Loss=0.0973]\n",
      "Participant 3/52 headAndGaze: 100%|██████████| 400/400 [00:20<00:00, 19.30it/s, Loss=0.0828]\n",
      "Participant 4/52 headAndGaze: 100%|██████████| 400/400 [00:17<00:00, 22.46it/s, Loss=0.0775]\n",
      "Participant 5/52 headAndGaze: 100%|██████████| 400/400 [00:17<00:00, 23.17it/s, Loss=0.0659]\n",
      "Participant 6/52 headAndGaze: 100%|██████████| 400/400 [00:20<00:00, 19.46it/s, Loss=0.0771]\n",
      "Participant 7/52 headAndGaze: 100%|██████████| 400/400 [00:18<00:00, 21.80it/s, Loss=0.0904]\n",
      "Participant 8/52 headAndGaze: 100%|██████████| 400/400 [00:18<00:00, 21.40it/s, Loss=0.0742]\n",
      "Participant 9/52 headAndGaze: 100%|██████████| 400/400 [00:20<00:00, 19.77it/s, Loss=0.0801]\n",
      "Participant 10/52 headAndGaze: 100%|██████████| 400/400 [00:18<00:00, 21.07it/s, Loss=0.0786]\n",
      "Participant 11/52 headAndGaze: 100%|██████████| 400/400 [00:19<00:00, 20.92it/s, Loss=0.0931]\n",
      "Participant 12/52 headAndGaze: 100%|██████████| 400/400 [00:17<00:00, 22.84it/s, Loss=0.0784]\n",
      "Participant 13/52 headAndGaze: 100%|██████████| 400/400 [00:17<00:00, 22.84it/s, Loss=0.0865]\n",
      "Participant 14/52 headAndGaze: 100%|██████████| 400/400 [00:17<00:00, 22.33it/s, Loss=0.0803]\n",
      "Participant 15/52 headAndGaze: 100%|██████████| 400/400 [00:17<00:00, 22.93it/s, Loss=0.0822]\n",
      "Participant 16/52 headAndGaze: 100%|██████████| 400/400 [00:18<00:00, 22.15it/s, Loss=0.0751]\n",
      "Participant 17/52 headAndGaze: 100%|██████████| 400/400 [00:18<00:00, 21.61it/s, Loss=0.0756]\n",
      "Participant 18/52 headAndGaze: 100%|██████████| 400/400 [00:18<00:00, 21.10it/s, Loss=0.0761]\n",
      "Participant 19/52 headAndGaze: 100%|██████████| 400/400 [00:18<00:00, 21.90it/s, Loss=0.0994]\n",
      "Participant 20/52 headAndGaze: 100%|██████████| 400/400 [00:17<00:00, 22.56it/s, Loss=0.0701]\n",
      "Participant 21/52 headAndGaze: 100%|██████████| 400/400 [00:18<00:00, 22.12it/s, Loss=0.0813]\n",
      "Participant 22/52 headAndGaze: 100%|██████████| 400/400 [00:18<00:00, 21.56it/s, Loss=0.0783]\n",
      "Participant 23/52 headAndGaze: 100%|██████████| 400/400 [00:16<00:00, 23.96it/s, Loss=0.074] \n",
      "Participant 24/52 headAndGaze: 100%|██████████| 400/400 [00:17<00:00, 23.22it/s, Loss=0.0736]\n",
      "Participant 25/52 headAndGaze: 100%|██████████| 400/400 [00:17<00:00, 23.06it/s, Loss=0.0807]\n",
      "Participant 26/52 headAndGaze: 100%|██████████| 400/400 [00:17<00:00, 23.24it/s, Loss=0.0857]\n",
      "Participant 27/52 headAndGaze: 100%|██████████| 400/400 [00:16<00:00, 23.69it/s, Loss=0.0757]\n",
      "Participant 28/52 headAndGaze: 100%|██████████| 400/400 [00:16<00:00, 23.65it/s, Loss=0.0838]\n",
      "Participant 29/52 headAndGaze: 100%|██████████| 400/400 [00:17<00:00, 23.23it/s, Loss=0.0669]\n",
      "Participant 30/52 headAndGaze: 100%|██████████| 400/400 [00:17<00:00, 23.40it/s, Loss=0.0778]\n",
      "Participant 31/52 headAndGaze: 100%|██████████| 400/400 [00:17<00:00, 23.31it/s, Loss=0.0894]\n",
      "Participant 32/52 headAndGaze: 100%|██████████| 400/400 [00:17<00:00, 23.28it/s, Loss=0.0619]\n",
      "Participant 33/52 headAndGaze: 100%|██████████| 400/400 [00:17<00:00, 22.92it/s, Loss=0.0687]\n",
      "Participant 34/52 headAndGaze: 100%|██████████| 400/400 [00:17<00:00, 22.97it/s, Loss=0.0681]\n",
      "Participant 35/52 headAndGaze: 100%|██████████| 400/400 [00:17<00:00, 23.03it/s, Loss=0.101] \n",
      "Participant 36/52 headAndGaze: 100%|██████████| 400/400 [00:17<00:00, 22.37it/s, Loss=0.0762]\n",
      "Participant 37/52 headAndGaze: 100%|██████████| 400/400 [00:17<00:00, 22.40it/s, Loss=0.0837]\n",
      "Participant 38/52 headAndGaze: 100%|██████████| 400/400 [00:16<00:00, 23.78it/s, Loss=0.0945]\n",
      "Participant 39/52 headAndGaze: 100%|██████████| 400/400 [00:17<00:00, 23.24it/s, Loss=0.0968]\n",
      "Participant 40/52 headAndGaze: 100%|██████████| 400/400 [00:17<00:00, 22.70it/s, Loss=0.0674]\n",
      "Participant 41/52 headAndGaze: 100%|██████████| 400/400 [00:17<00:00, 23.40it/s, Loss=0.0664]\n",
      "Participant 42/52 headAndGaze: 100%|██████████| 400/400 [00:17<00:00, 23.16it/s, Loss=0.0806]\n",
      "Participant 43/52 headAndGaze: 100%|██████████| 400/400 [00:17<00:00, 22.65it/s, Loss=0.0905]\n",
      "Participant 44/52 headAndGaze: 100%|██████████| 400/400 [00:16<00:00, 23.59it/s, Loss=0.077] \n",
      "Participant 45/52 headAndGaze: 100%|██████████| 400/400 [00:17<00:00, 23.37it/s, Loss=0.0654]\n",
      "Participant 46/52 headAndGaze: 100%|██████████| 400/400 [00:17<00:00, 23.42it/s, Loss=0.0708]\n",
      "Participant 47/52 headAndGaze: 100%|██████████| 400/400 [00:16<00:00, 23.87it/s, Loss=0.0674]\n",
      "Participant 48/52 headAndGaze: 100%|██████████| 400/400 [00:19<00:00, 20.80it/s, Loss=0.0767]\n",
      "Participant 49/52 headAndGaze: 100%|██████████| 400/400 [00:20<00:00, 19.20it/s, Loss=0.0846]\n",
      "Participant 50/52 headAndGaze: 100%|██████████| 400/400 [00:19<00:00, 20.89it/s, Loss=0.0789]\n",
      "Participant 51/52 headAndGaze: 100%|██████████| 400/400 [00:18<00:00, 21.45it/s, Loss=0.0654]\n",
      "Participant 52/52 headAndGaze: 100%|██████████| 400/400 [00:18<00:00, 21.58it/s, Loss=0.0827]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Condition: nod\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Participant 1/52 nod: 100%|██████████| 400/400 [00:17<00:00, 22.64it/s, Loss=0.273]\n",
      "Participant 2/52 nod: 100%|██████████| 400/400 [00:17<00:00, 23.08it/s, Loss=0.312]\n",
      "Participant 3/52 nod: 100%|██████████| 400/400 [00:17<00:00, 22.50it/s, Loss=0.23] \n",
      "Participant 4/52 nod: 100%|██████████| 400/400 [00:17<00:00, 22.45it/s, Loss=0.228]\n",
      "Participant 5/52 nod: 100%|██████████| 400/400 [00:17<00:00, 22.79it/s, Loss=0.267]\n",
      "Participant 6/52 nod: 100%|██████████| 400/400 [00:17<00:00, 22.59it/s, Loss=0.229]\n",
      "Participant 7/52 nod: 100%|██████████| 400/400 [00:17<00:00, 22.43it/s, Loss=0.228]\n",
      "Participant 8/52 nod: 100%|██████████| 400/400 [00:17<00:00, 22.58it/s, Loss=0.23] \n",
      "Participant 9/52 nod: 100%|██████████| 400/400 [00:17<00:00, 23.10it/s, Loss=0.227]\n",
      "Participant 10/52 nod: 100%|██████████| 400/400 [00:17<00:00, 23.18it/s, Loss=0.258]\n",
      "Participant 11/52 nod: 100%|██████████| 400/400 [00:17<00:00, 22.73it/s, Loss=0.237]\n",
      "Participant 12/52 nod: 100%|██████████| 400/400 [00:17<00:00, 22.53it/s, Loss=0.247]\n",
      "Participant 13/52 nod: 100%|██████████| 400/400 [00:18<00:00, 21.57it/s, Loss=0.247]\n",
      "Participant 14/52 nod: 100%|██████████| 400/400 [00:17<00:00, 22.86it/s, Loss=0.272]\n",
      "Participant 15/52 nod: 100%|██████████| 400/400 [00:17<00:00, 22.77it/s, Loss=0.278]\n",
      "Participant 16/52 nod: 100%|██████████| 400/400 [00:17<00:00, 22.79it/s, Loss=0.258]\n",
      "Participant 17/52 nod: 100%|██████████| 400/400 [00:17<00:00, 23.06it/s, Loss=0.256]\n",
      "Participant 18/52 nod: 100%|██████████| 400/400 [00:17<00:00, 22.42it/s, Loss=0.224]\n",
      "Participant 19/52 nod: 100%|██████████| 400/400 [00:17<00:00, 22.54it/s, Loss=0.273]\n",
      "Participant 20/52 nod: 100%|██████████| 400/400 [00:17<00:00, 22.76it/s, Loss=0.23] \n",
      "Participant 21/52 nod: 100%|██████████| 400/400 [00:17<00:00, 22.66it/s, Loss=0.244]\n",
      "Participant 22/52 nod: 100%|██████████| 400/400 [00:17<00:00, 23.36it/s, Loss=0.247]\n",
      "Participant 23/52 nod: 100%|██████████| 400/400 [00:18<00:00, 21.53it/s, Loss=0.26] \n",
      "Participant 24/52 nod: 100%|██████████| 400/400 [00:17<00:00, 22.29it/s, Loss=0.223]\n",
      "Participant 25/52 nod: 100%|██████████| 400/400 [00:18<00:00, 21.92it/s, Loss=0.231]\n",
      "Participant 26/52 nod: 100%|██████████| 400/400 [00:17<00:00, 22.60it/s, Loss=0.223]\n",
      "Participant 27/52 nod: 100%|██████████| 400/400 [00:18<00:00, 21.36it/s, Loss=0.241]\n",
      "Participant 28/52 nod: 100%|██████████| 400/400 [00:19<00:00, 20.95it/s, Loss=0.239]\n",
      "Participant 29/52 nod: 100%|██████████| 400/400 [00:19<00:00, 20.12it/s, Loss=0.266]\n",
      "Participant 30/52 nod: 100%|██████████| 400/400 [00:17<00:00, 23.08it/s, Loss=0.24] \n",
      "Participant 31/52 nod: 100%|██████████| 400/400 [00:17<00:00, 23.03it/s, Loss=0.249]\n",
      "Participant 32/52 nod: 100%|██████████| 400/400 [00:16<00:00, 23.89it/s, Loss=0.245]\n",
      "Participant 33/52 nod: 100%|██████████| 400/400 [00:16<00:00, 23.79it/s, Loss=0.229]\n",
      "Participant 34/52 nod: 100%|██████████| 400/400 [00:17<00:00, 23.19it/s, Loss=0.251]\n",
      "Participant 35/52 nod: 100%|██████████| 400/400 [00:16<00:00, 23.65it/s, Loss=0.254]\n",
      "Participant 36/52 nod: 100%|██████████| 400/400 [00:16<00:00, 23.73it/s, Loss=0.237]\n",
      "Participant 37/52 nod: 100%|██████████| 400/400 [00:20<00:00, 19.39it/s, Loss=0.265]\n",
      "Participant 38/52 nod: 100%|██████████| 400/400 [00:17<00:00, 23.36it/s, Loss=0.252]\n",
      "Participant 39/52 nod: 100%|██████████| 400/400 [00:17<00:00, 22.63it/s, Loss=0.232]\n",
      "Participant 40/52 nod: 100%|██████████| 400/400 [00:17<00:00, 23.16it/s, Loss=0.242]\n",
      "Participant 41/52 nod: 100%|██████████| 400/400 [00:17<00:00, 23.51it/s, Loss=0.244]\n",
      "Participant 42/52 nod: 100%|██████████| 400/400 [00:16<00:00, 23.95it/s, Loss=0.24] \n",
      "Participant 43/52 nod: 100%|██████████| 400/400 [00:17<00:00, 23.34it/s, Loss=0.254]\n",
      "Participant 44/52 nod: 100%|██████████| 400/400 [00:16<00:00, 24.26it/s, Loss=0.248]\n",
      "Participant 45/52 nod: 100%|██████████| 400/400 [00:16<00:00, 23.54it/s, Loss=0.248]\n",
      "Participant 46/52 nod: 100%|██████████| 400/400 [00:16<00:00, 23.86it/s, Loss=0.24] \n",
      "Participant 47/52 nod: 100%|██████████| 400/400 [00:16<00:00, 23.65it/s, Loss=0.264]\n",
      "Participant 48/52 nod: 100%|██████████| 400/400 [00:16<00:00, 23.53it/s, Loss=0.249]\n",
      "Participant 49/52 nod: 100%|██████████| 400/400 [00:17<00:00, 22.76it/s, Loss=0.238]\n",
      "Participant 50/52 nod: 100%|██████████| 400/400 [00:20<00:00, 19.46it/s, Loss=0.222]\n",
      "Participant 51/52 nod: 100%|██████████| 400/400 [00:18<00:00, 21.77it/s, Loss=0.241]\n",
      "Participant 52/52 nod: 100%|██████████| 400/400 [00:17<00:00, 22.36it/s, Loss=0.24] \n"
     ]
    }
   ],
   "source": [
    "import utils\n",
    "from TCN import *\n",
    "import torch\n",
    "import numpy as np\n",
    "import json\n",
    "import train\n",
    "\n",
    "model_folder = \"Results/LOSO_a200_b300_f44_seq43_finalRounds/Models\"\n",
    "model_base_name = \"TCNAE_1\"\n",
    "conditions = [\"gaze\", \"headAndGaze\", \"nod\"]\n",
    "\n",
    "fps = 90\n",
    "f = 44\n",
    "b = 300\n",
    "a = 200\n",
    "\n",
    "for cond in conditions:\n",
    "    print(f\"Condition: {cond}\")\n",
    "    model_name = f\"{model_base_name}_{cond}\"\n",
    "    with open(os.path.join(model_folder, model_name + \"_info.json\"), 'r') as file:\n",
    "        model_info = json.load(file)\n",
    "\n",
    "    angles_correct = np.load(f\"../Data/Dataset_Prepare/angles_fps{fps}_{cond}_Correct_f{f}_b{b}_a{a}_finalRounds.npy\")\n",
    "    angles_incorrect = np.load(f\"../Data/Dataset_Prepare/angles_fps{fps}_{cond}_Incorrect_f{f}_b{b}_a{a}_finalRounds.npy\")\n",
    "    names_correct = np.load(f\"../Data/Dataset_Prepare/names_fps{fps}_{cond}_Correct_f{f}_b{b}_a{a}_finalRounds.npy\")\n",
    "    names_incorrect = np.load(f\"../Data/Dataset_Prepare/names_fps{fps}_{cond}_Incorrect_f{f}_b{b}_a{a}_finalRounds.npy\")\n",
    "\n",
    "    \n",
    "    pat_names = np.unique(names_correct)\n",
    "    save_folder_condition = utils.create_unique_folder(os.path.join(save_folder, cond))\n",
    "    for k, name in enumerate(pat_names):\n",
    "        train_fold = angles_correct[names_correct != name]\n",
    "        test_fold_correct = angles_correct[names_correct == name]\n",
    "        test_fold_incorrect = angles_incorrect[names_incorrect == name]\n",
    "\n",
    "        model = TCNAE(**model_info[\"model_parameter\"])\n",
    "        model, _ = train.train_autoencoder(\n",
    "            model=model,\n",
    "            train_data=train_fold,\n",
    "            batch_size=model_info[\"train_parameter\"][\"batch_size\"],\n",
    "            num_epochs=model_info[\"train_parameter\"][\"num_epochs\"],\n",
    "            learning_rate=model_info[\"train_parameter\"][\"learning_rate\"],\n",
    "            criterion=torch.nn.MSELoss(),\n",
    "            use_gpu=model_info[\"train_parameter\"][\"use_gpu\"],\n",
    "            desc_tqdm=f\"Participant {k+1}/{len(pat_names)} {cond}\"\n",
    "        )\n",
    "\n",
    "        mse_train, mse_correct, mse_incorrect = train.test_autoencoder(\n",
    "            train_samples=train_fold,\n",
    "            correct_samples=test_fold_correct,\n",
    "            incorrect_samples=test_fold_incorrect,\n",
    "            model=model,\n",
    "            use_gpu=model_info[\"train_parameter\"][\"use_gpu\"],\n",
    "            batch_size=model_info[\"train_parameter\"][\"batch_size\"]\n",
    "        )\n",
    "\n",
    "        t = np.percentile(mse_train.cpu().numpy(), model_info[\"th_perc\"])\n",
    "\n",
    "        results = {\n",
    "            \"participant\": name,\n",
    "            \"mse_correct\": mse_correct.cpu().numpy().tolist(),\n",
    "            \"mse_incorrect\": mse_incorrect.cpu().numpy().tolist() if mse_incorrect is not None else [],\n",
    "            \"threshold\": t\n",
    "        }\n",
    "        with open(os.path.join(save_folder_condition, f\"Results_{name}.json\"), 'w') as file:\n",
    "            json.dump(results, file, indent=4)\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Check errors and estimate effect size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'gaze': {'with': [0, 0, 1, 0, 2, 1, 0, 0, 0, 1, 1, 1, 0, 0, 2, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0], 'without': [0, 0, 5, 1, 2, 1, 0, 5, 0, 3, 11, 4, 3, 1, 6, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 7, 3, 10, 0, 5, 2, 3, 2, 1, 0, 0, 4, 0, 0, 1, 3, 0, 2, 1, 0, 0, 2, 0, 0, 9, 0, 0]}, 'headAndGaze': {'with': [0, 0, 0, 0, 1, 0, 0, 1, 0, 2, 1, 0, 3, 0, 0, 0, 0, 1, 0, 0, 2, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'without': [0, 1, 0, 0, 6, 0, 0, 2, 1, 2, 2, 0, 3, 0, 1, 0, 0, 2, 0, 1, 3, 0, 0, 0, 1, 6, 0, 0, 1, 0, 0, 0, 0, 9, 0, 0, 0, 0, 0, 0, 4, 0, 0, 0, 1, 0, 0, 0, 0, 12, 0, 0]}, 'nod': {'with': [0, 3, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 2, 2, 0, 0, 0, 0, 0, 0, 0, 1, 2, 0, 2, 0, 0, 1, 0, 2, 0, 3, 4, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 2, 0, 0], 'without': [0, 3, 0, 1, 1, 1, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 3, 4, 0, 1, 0, 0, 0, 0, 1, 4, 7, 0, 4, 2, 0, 2, 0, 7, 3, 3, 8, 1, 0, 2, 0, 1, 0, 0, 0, 2, 0, 1, 0, 2, 0, 2]}}\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "datapath = 'Results/PowerMeasurements'\n",
    "\n",
    "conditions = ['gaze', 'headAndGaze', 'nod']\n",
    "corrects = {x: {'with': [], 'without': []} for x in conditions}\n",
    "incorrects = {x: {'with': [], 'without': []} for x in conditions}\n",
    "\n",
    "# cond = conditions[0]\n",
    "for cond in conditions:\n",
    "    datapath_condition = os.path.join(datapath, cond)\n",
    "\n",
    "    files = os.listdir(datapath_condition)\n",
    "\n",
    "    file = files[2]\n",
    "    for file in files:\n",
    "\n",
    "        with open(os.path.join(datapath_condition, file), 'r') as f:\n",
    "            data = json.load(f)\n",
    "\n",
    "        incorrect_without = len(data['mse_incorrect'])\n",
    "        incorrect_with = np.sum(np.array(data['mse_incorrect']) < data['threshold']) # less, because that is the number of incorrect selections even with the system, so the mse is smaller then the threshold even it is a incorrect selection\n",
    "\n",
    "        incorrects[cond]['with'].append(incorrect_with)\n",
    "        incorrects[cond]['without'].append(incorrect_without)\n",
    "\n",
    "        corrects_without = len(data['mse_correct'])\n",
    "        corrects_with = np.sum(np.array(data['mse_correct']) <= data['threshold'])\n",
    "\n",
    "        corrects[cond]['with'].append(corrects_with)\n",
    "        corrects[cond]['without'].append(corrects_without)\n",
    "\n",
    "print(incorrects)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ -1,  -1,  -6, -10,  -1,  -9, -15,   0,  -3,  -2,   6,  -1,   2,\n",
       "         1,   3,   1,  -9,   0,  -2,  -8,  -4,  -9,   0,  -4, -10,  -6,\n",
       "         2,   2,  -3,  -4,   0,   1,  -2,  -1,  -6,  -2,   1,  -2, -17,\n",
       "        -4,   2,  -1,  -8,  -1, -24,  -3,  -4,   0,  -3,   2,  -2, -33])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cond = conditions[0]\n",
    "\n",
    "calc_d = lambda a, b, c, d: (np.array(a) - np.array(b)) + (np.array(c) - np.array(d))\n",
    "\n",
    "d = calc_d(corrects[cond]['with'], corrects[cond]['without'], incorrects[cond]['without'], incorrects[cond]['with'])\n",
    "d\n",
    "\n",
    "# np.array(corrects[cond]['without']) - np.array(corrects[cond]['with'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Condition: gaze\n",
      "T-statistic: 0.000\n",
      "P-value: 0.000\n",
      "Reject the null hypothesis: x is significantly less than y\n",
      "\n",
      "Condition: headAndGaze\n",
      "T-statistic: 0.000\n",
      "P-value: 0.000\n",
      "Reject the null hypothesis: x is significantly less than y\n",
      "\n",
      "Condition: nod\n",
      "T-statistic: 0.000\n",
      "P-value: 0.000\n",
      "Reject the null hypothesis: x is significantly less than y\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from scipy.stats import ttest_ind, ttest_rel, wilcoxon\n",
    "conditions = [\"gaze\", \"headAndGaze\", \"nod\"]\n",
    "# cond = conditions[0]\n",
    "for cond in conditions:\n",
    "    print(f\"Condition: {cond}\")\n",
    "    # Example data for independent samples\n",
    "    x = np.array(incorrects[cond]['with'])\n",
    "    y = np.array(incorrects[cond]['without'])\n",
    "\n",
    "    # Perform one-sided t-test (x < y)\n",
    "    # t_stat, p_value = ttest_rel(x, y, alternative='less')\n",
    "    t_stat, p_value = wilcoxon(x, y, alternative='less')\n",
    "\n",
    "    print(f\"T-statistic: {t_stat:.3f}\")\n",
    "    print(f\"P-value: {p_value:.3f}\")\n",
    "\n",
    "    if p_value < 0.05:\n",
    "        print(\"Reject the null hypothesis: x is significantly less than y\")\n",
    "    else:\n",
    "        print(\"Fail to reject the null hypothesis: x is not significantly less than y\")\n",
    "    \n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3.145332252154177e-05"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Condition: gaze\n",
      "Mean incorrect with: 0.288\n",
      "Mean incorrect without: 1.923\n",
      "Cohen's d: 0.836\n",
      "Required sample size per group: 18\n",
      "\n",
      "Condition: headAndGaze\n",
      "Mean incorrect with: 0.269\n",
      "Mean incorrect without: 1.115\n",
      "Cohen's d: 0.486\n",
      "Required sample size per group: 53\n",
      "\n",
      "Condition: nod\n",
      "Mean incorrect with: 0.558\n",
      "Mean incorrect without: 1.308\n",
      "Cohen's d: 0.489\n",
      "Required sample size per group: 52\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Estimate effectsize for power analysis\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy import stats\n",
    "from statsmodels.stats.power import TTestIndPower\n",
    "\n",
    "for cond in conditions:\n",
    "    print(f\"Condition: {cond}\")\n",
    "    # Example data\n",
    "    group1 = np.array(incorrects[cond]['without'])\n",
    "    group2 = np.array(incorrects[cond]['with'])\n",
    "\n",
    "    # Calculate means and standard deviations\n",
    "    mean1 = np.mean(group1)\n",
    "    mean2 = np.mean(group2)\n",
    "    std1 = np.std(group1, ddof=1)\n",
    "    std2 = np.std(group2, ddof=1)\n",
    "\n",
    "    # Calculate pooled standard deviation\n",
    "    n1 = len(group1)\n",
    "    n2 = len(group2)\n",
    "    pooled_std = np.sqrt(((n1 - 1) * std1**2 + (n2 - 1) * std2**2) / (n1 + n2 - 2))\n",
    "\n",
    "    # Calculate Cohen's d\n",
    "    cohen_d = (mean1 - mean2) / pooled_std\n",
    "    print(f\"Mean incorrect with: {mean2:.3f}\")\n",
    "    print(f\"Mean incorrect without: {mean1:.3f}\")\n",
    "    print(f\"Cohen's d: {cohen_d:.3f}\")\n",
    "\n",
    "    # Perform power analysis\n",
    "    alpha = 0.05  # significance level\n",
    "    power = 0.80  # desired power\n",
    "    analysis = TTestIndPower()\n",
    "    sample_size = analysis.solve_power(effect_size=cohen_d, alpha=alpha, power=power, alternative='larger')\n",
    "    print(f\"Required sample size per group: {sample_size:.0f}\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "52.392351556853164"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 1 0 2 1 0 0 0 1 1 1 0 0 2 0 1 0 0 0 0 0 0 1 0 1 0 0 0 0 0 0 1 0 0 0 0\n",
      " 0 0 1 0 0 0 1 0 0 0 0 0 0 0 0]\n",
      "[ 0  0  5  1  2  1  0  5  0  3 11  4  3  1  6  1  1  0  0  0  0  0  0  1\n",
      "  0  7  3 10  0  5  2  3  2  1  0  0  4  0  0  1  3  0  2  1  0  0  2  0\n",
      "  0  9  0  0]\n",
      "[0 0 0 0 1 0 0 1 0 2 1 0 3 0 0 0 0 1 0 0 2 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0]\n",
      "[ 0  1  0  0  6  0  0  2  1  2  2  0  3  0  1  0  0  2  0  1  3  0  0  0\n",
      "  1  6  0  0  1  0  0  0  0  9  0  0  0  0  0  0  4  0  0  0  1  0  0  0\n",
      "  0 12  0  0]\n",
      "[0 3 0 0 1 0 0 0 0 0 1 0 0 0 0 0 2 2 0 0 0 0 0 0 0 1 2 0 2 0 0 1 0 2 0 3 4\n",
      " 0 0 1 0 0 0 0 0 1 0 1 0 2 0 0]\n",
      "[0 3 0 1 1 1 0 1 0 0 1 0 0 0 0 0 3 4 0 1 0 0 0 0 1 4 7 0 4 2 0 2 0 7 3 3 8\n",
      " 1 0 2 0 1 0 0 0 2 0 1 0 2 0 2]\n"
     ]
    }
   ],
   "source": [
    "for cond in conditions:\n",
    "    x = np.array(incorrects[cond]['with'])\n",
    "    y = np.array(incorrects[cond]['without'])\n",
    "    print(x)\n",
    "    print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ -1,  -1,  -6, -10,  -1,  -9, -15,   0,  -3,  -2,   6,  -1,   2,\n",
       "         1,   3,   1,  -9,   0,  -2,  -8,  -4,  -9,   0,  -4, -10,  -6,\n",
       "         2,   2,  -3,  -4,   0,   1,  -2,  -1,  -6,  -2,   1,  -2, -17,\n",
       "        -4,   2,  -1,  -8,  -1, -24,  -3,  -4,   0,  -3,   2,  -2, -33])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Condition: gaze\n",
      "Wilcoxon statistic: 0.000\n",
      "P-value: 0.000\n",
      "Reject the null hypothesis: x is significantly less than y\n",
      "Rank-biserial correlation: -6.275\n",
      "Standardized test statistic (r): -0.870\n",
      "Required sample size per group: 16\n",
      "Power for sample size 50: 0.997\n",
      "\n",
      "Condition: headAndGaze\n",
      "Wilcoxon statistic: 0.000\n",
      "P-value: 0.000\n",
      "Reject the null hypothesis: x is significantly less than y\n",
      "Rank-biserial correlation: -6.275\n",
      "Standardized test statistic (r): -0.870\n",
      "Required sample size per group: 16\n",
      "Power for sample size 50: 0.997\n",
      "\n",
      "Condition: nod\n",
      "Wilcoxon statistic: 0.000\n",
      "P-value: 0.000\n",
      "Reject the null hypothesis: x is significantly less than y\n",
      "Rank-biserial correlation: -6.275\n",
      "Standardized test statistic (r): -0.870\n",
      "Required sample size per group: 16\n",
      "Power for sample size 50: 0.997\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from scipy.stats import wilcoxon, norm\n",
    "from statsmodels.stats.power import NormalIndPower\n",
    "\n",
    "\n",
    "for cond in conditions:\n",
    "    print(f\"Condition: {cond}\")\n",
    "\n",
    "    # Example data for paired samples\n",
    "    x = np.array(incorrects[cond]['with'])\n",
    "    y = np.array(incorrects[cond]['without'])\n",
    "\n",
    "    # Perform one-sided Wilcoxon signed-rank test (x < y)\n",
    "    # d = x - y\n",
    "    # stat, p_value = wilcoxon(d, alternative='less')\n",
    "    stat, p_value = wilcoxon(x, y, alternative='less')\n",
    "\n",
    "    print(f\"Wilcoxon statistic: {stat:.3f}\")\n",
    "    print(f\"P-value: {p_value:.3f}\")\n",
    "\n",
    "    if p_value < 0.05:\n",
    "        print(\"Reject the null hypothesis: x is significantly less than y\")\n",
    "    else:\n",
    "        print(\"Fail to reject the null hypothesis: x is not significantly less than y\")\n",
    "\n",
    "    # Calculate effect size (rank-biserial correlation)\n",
    "    n = len(x)\n",
    "    rank_biserial = (stat - (n * (n + 1) / 4)) / np.sqrt((n * (n + 1) * (2 * n + 1)) / 24)\n",
    "    print(f\"Rank-biserial correlation: {rank_biserial:.3f}\")\n",
    "\n",
    "    # Calculate standardized test statistic (r)\n",
    "    z = (stat - (n * (n + 1) / 4)) / np.sqrt((n * (n + 1) * (2 * n + 1)) / 24)\n",
    "    r = z / np.sqrt(n)\n",
    "    print(f\"Standardized test statistic (r): {r:.3f}\")\n",
    "\n",
    "    # Perform power analysis to estimate required sample size\n",
    "    alpha = 0.05  # significance level\n",
    "    power = 0.80   # desired power\n",
    "    effect_size = np.abs(r)  # use rank-biserial correlation as effect size\n",
    "\n",
    "    analysis = NormalIndPower()\n",
    "    sample_size = analysis.solve_power(effect_size=effect_size, alpha=alpha, power=power, nobs1=None, ratio=1.0, alternative='larger')\n",
    "    print(f\"Required sample size per group: {sample_size:.0f}\")\n",
    "\n",
    "    # Compare power for a fixed sample size\n",
    "    fixed_sample_size = 50\n",
    "    power_estimate = analysis.solve_power(effect_size=effect_size, alpha=alpha, nobs1=fixed_sample_size, alternative='larger')\n",
    "    print(f\"Power for sample size {fixed_sample_size}: {power_estimate:.3f}\")\n",
    "\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Condition: gaze\n",
      "Median difference: 2.000\n",
      "Effect size: 0.707\n",
      "Required sample size for power 0.80: 25\n",
      "Required sample size for power 0.90: 35\n",
      "Required sample size for power 0.95: 44\n",
      "\n",
      "\n",
      "Condition: headAndGaze\n",
      "Median difference: 1.000\n",
      "Effect size: 0.311\n",
      "Required sample size for power 0.80: 129\n",
      "Required sample size for power 0.90: 178\n",
      "Required sample size for power 0.95: 225\n",
      "\n",
      "\n",
      "Condition: nod\n",
      "Median difference: 1.000\n",
      "Effect size: 0.704\n",
      "Required sample size for power 0.80: 26\n",
      "Required sample size for power 0.90: 35\n",
      "Required sample size for power 0.95: 44\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import statsmodels.stats.power as smp\n",
    "\n",
    "cond = conditions[0]\n",
    "\n",
    "for cond in conditions:\n",
    "    print(f\"Condition: {cond}\")\n",
    "\n",
    "    errors_with = np.array(incorrects[cond]['with'])\n",
    "    errors_without = np.array(incorrects[cond]['without'])\n",
    "\n",
    "    not_zero_errors_idx = np.where(errors_without != 0)\n",
    "    errors_with = errors_with[not_zero_errors_idx]\n",
    "    errors_without = errors_without[not_zero_errors_idx]\n",
    "\n",
    "    diff = errors_without - errors_with\n",
    "\n",
    "    r = np.median(diff) / np.std(diff)\n",
    "    print(f\"Median difference: {np.median(diff):.3f}\")\n",
    "    print(f\"Effect size: {r:.3f}\")\n",
    "\n",
    "    # Define parameters\n",
    "    effect_size = r    \n",
    "    alpha = 0.05       \n",
    "    power = 0.95        \n",
    "    alternative = 'larger'  # Because we expect fewer incorrect selections\n",
    "\n",
    "    # Compute sample size\n",
    "    for power in [0.8, 0.9, 0.95]:\n",
    "        sample_size = smp.TTestIndPower().solve_power(effect_size, alpha=alpha, power=power, alternative=alternative)\n",
    "\n",
    "        sample_size = int(round(sample_size))\n",
    "        print(f\"Required sample size for power {power:.2f}: {sample_size}\")\n",
    "    print()\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 3 0 0 1 0 0 0 0 0 1 0 0 0 0 0 2 2 0 0 0 0 0 0 0 1 2 0 2 0 0 1 0 2 0 3 4\n",
      " 0 0 1 0 0 0 0 0 1 0 1 0 2 0 0]\n",
      "[0 3 0 1 1 1 0 1 0 0 1 0 0 0 0 0 3 4 0 1 0 0 0 0 1 4 7 0 4 2 0 2 0 7 3 3 8\n",
      " 1 0 2 0 1 0 0 0 2 0 1 0 2 0 2]\n",
      "[0 0 0 1 0 1 0 1 0 0 0 0 0 0 0 0 1 2 0 1 0 0 0 0 1 3 5 0 2 2 0 1 0 5 3 0 4\n",
      " 1 0 1 0 1 0 0 0 1 0 0 0 0 0 2]\n"
     ]
    }
   ],
   "source": [
    "errors_with = np.array(incorrects[cond]['with'])\n",
    "errors_without = np.array(incorrects[cond]['without'])\n",
    "print(errors_with)\n",
    "print(errors_without)\n",
    "\n",
    "diff = errors_without - errors_with\n",
    "print(diff)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "MAIA",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
